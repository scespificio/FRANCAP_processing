{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0330e5dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ISFROM_LOGO', 'CLE', 'CODE OP', 'DATE OP', 'MENTION SPECIFIQUE',\n",
       "       'CATEGORIE', 'INTITULE', 'GENCOD', 'MARQUE', 'ORIGINE', 'MECAPROMO',\n",
       "       'RONDE DES MARQUES', 'DESCRIPTIF', 'PRIX AU KG', 'PVC MAXI', 'BONUS',\n",
       "       'BONUS EN %', 'RI EN €', 'RI EN %', 'PVC NET', 'LOT VIRTUEL',\n",
       "       'PRIX AU KG DU LOT VIRTUEL', 'FORMAT GV', 'FORMAT MV', 'FORMAT MVK',\n",
       "       'FORMAT PV', 'PRODUIT DE UNE', 'PRODUIT EN DER', 'MISE EN AVANT',\n",
       "       'VIDE_2', 'PICTO', 'SR', 'CATALOG', 'CATALOG_MARKET', 'AFFICHE',\n",
       "       'SELECTION FRANCAP', 'SELECTION CODIFRANCE', 'INFO COMPLEMENTAIRES',\n",
       "       'PHOTO1', 'PHOTO2', 'PHOTO3', 'PHOTO4', 'PHOTO5', 'PHOTO6', 'PHOTO7',\n",
       "       'PHOTO8', 'DESCRIPTIF_2', 'PRIX AU KG_2', 'PRIX AU KG DU LOT VIRTUEL_2',\n",
       "       'DESCRIPTIF_3', 'PRIX AU KG_3', 'PRIX AU KG DU LOT VIRTUEL_3',\n",
       "       'DESCRIPTIF_4', 'PRIX AU KG_4', 'PRIX AU KG DU LOT VIRTUEL_4',\n",
       "       'DESCRIPTIF_5', 'PRIX AU KG_5', 'PRIX AU KG DU LOT VIRTUEL_5',\n",
       "       'DESCRIPTIF_6', 'PRIX AU KG_6', 'PRIX AU KG DU LOT VIRTUEL_6',\n",
       "       'SUPER_Page', 'SUPER_Rang', 'SUPER_Case', 'EXPRESS_Page',\n",
       "       'EXPRESS_Rang', 'EXPRESS_Case', 'MARKET_Page', 'MARKET_Rang',\n",
       "       'MARKET_Case', 'REGIO_Page', 'REGIO_Rang', 'REGIO_Case', 'SUPER_WP',\n",
       "       'EXPRESS_WP', 'MARKET_WP'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "import sys\n",
    "\n",
    "# Chemin du fichier Excel\n",
    "fichier_excel = '/Users/stevecostalat/Downloads/SAISIE_CODIFRANCE_OP2507_2025-06-21 12_51_16.407839.xlsx'\n",
    "\n",
    "# Charger la première feuille par défaut\n",
    "df = pd.read_excel(fichier_excel)\n",
    "df['RONDE DES MARQUES'] = df['RONDE DES MARQUES'].apply(lambda x : True if str(x).strip() in ['X', 'x'] else False)\n",
    "for i in range(2,7,1):\n",
    "    df[f\"DESCRIPTIF_{i}\"] = df[f\"DESCRIPTIF_{i}\"].fillna('').astype('str')\n",
    "    df[f\"PRIX AU KG_{i}\"] = df[f\"PRIX AU KG_{i}\"].fillna('').astype('str')\n",
    "    df[f\"PRIX AU KG DU LOT VIRTUEL_{i}\"] = df[f\"PRIX AU KG DU LOT VIRTUEL_{i}\"].fillna('').astype('str')\n",
    "\n",
    "# Afficher les 5 premières lignes\n",
    "df['GENCOD'] = df['GENCOD'].astype('int').astype('str')\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b42a5624",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9588d44d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "regex_saveur = r\"[oO]u en|[eE]xiste aussi(?: en)?|\\b[Oo]u\\b\"\n",
    "regex_le_la = r\"^(Le|La|L')\\s*\"\n",
    "# Amélioration : ignorer les nombres suivis de °, %, ou accolés à des lettres, ou non suivis d'un mot\n",
    "regex_unitaire = r\"\\b\\d+(?!\\s?(cm|g|mg|ml|cl|l)\\b|\\s*°|\\s*%|\\w|,)\\b\"\n",
    "# Amélioration : accepte aussi les nombres à virgule (ex: 381,9 g)\n",
    "regex_contenu = r\"\\b(\\d+(?:[.,]\\d+)?\\s?(cm|g|mg|ml|cl|l))\\b\"\n",
    "\n",
    "\n",
    "\n",
    "# Découpe la chaîne en utilisant la regex regex_saveur et aussi les virgules\n",
    "def split_by_saveur_and_comma(text):\n",
    "    \"\"\"\n",
    "    Découpe une chaîne de saveurs/packagings selon les connecteurs ('ou', 'existe aussi en', etc.) et les virgules,\n",
    "    puis nettoie chaque élément pour ne garder que les saveurs pertinentes.\n",
    "    \"\"\"\n",
    "    # Découpe d'abord selon les connecteurs de saveurs\n",
    "    parts = re.split(regex_saveur, text)\n",
    "    result = []\n",
    "    for part in parts:\n",
    "        cleaned = re.sub(regex_saveur, '', part, flags=re.IGNORECASE).strip()\n",
    "        if not cleaned:\n",
    "            continue\n",
    "        # Découpe par virgule, nettoie chaque sous-partie\n",
    "        for p in cleaned.split(','):\n",
    "            p_clean = p.strip()\n",
    "            # Ignore les lignes commençant par Le/La/L' et contenant une taille/unité\n",
    "            if re.match(regex_le_la, p_clean) and (re.search(regex_contenu, p_clean) or re.search(regex_unitaire, p_clean)):\n",
    "                continue\n",
    "            # Si ce n'est pas un packaging, retire la taille/unité éventuelle\n",
    "            if not re.match(regex_le_la, p_clean):\n",
    "                p_clean = re.sub(regex_contenu, '', p_clean).strip()\n",
    "                # Coupe à la première occurrence d'un nombre unitaire\n",
    "                p_clean = re.split(regex_unitaire, p_clean, maxsplit=1)[0].strip()\n",
    "            if p_clean:\n",
    "                result.append(p_clean)\n",
    "    return result\n",
    "\n",
    "\n",
    "\n",
    "def parse_descriptif_lines_into_dict(row):\n",
    "    \"\"\"\n",
    "    Parse chaque ligne du champ 'DESCRIPTIF' pour extraire les saveurs, packaging, taille et unité.\n",
    "    Retourne une liste de dictionnaires structurés.\n",
    "    \"\"\"\n",
    "\n",
    "    results = []\n",
    "    lines = str(row['DESCRIPTIF']).split('\\n')\n",
    "\n",
    "    for line in lines:\n",
    "        # Recherche de la taille/unité via regex\n",
    "        match_c = re.search(regex_contenu, line)\n",
    "        match_u = re.search(regex_unitaire, line)\n",
    "        saveurs = split_by_saveur_and_comma(line)\n",
    "\n",
    "        if match_c or match_u:\n",
    "            match = match_c if match_c else match_u\n",
    "            packaging = line[:match.start()].strip()\n",
    "            size = ''.join(filter(str.isdigit, match.group(0)))\n",
    "            # Récupère l'unité (lettres) si regex_contenu, sinon tente après le match unitaire\n",
    "            unit = (\n",
    "                ''.join(filter(str.isalpha, match.group(0)))\n",
    "                if match_c else\n",
    "                (line[match_u.end():].strip().split()[0] if match_u and line[match_u.end():].strip() else None)\n",
    "            )\n",
    "            # Retirer packaging, size et unit de la ligne pour misc (version condensée)\n",
    "            misc = line\n",
    "            for val in (packaging, size, unit):\n",
    "                if val:\n",
    "                    misc = misc.replace(val, '', 1)\n",
    "            misc = misc.strip()\n",
    "            results.append({\n",
    "                'saveurs': saveurs,\n",
    "                'packaging': packaging if packaging else None,\n",
    "                'size': size if size else None,\n",
    "                'unit': unit if unit else None,\n",
    "                'misc': misc if misc else None\n",
    "            })\n",
    "        else:\n",
    "            if saveurs[0]== line.strip if line.strip() else None:\n",
    "                # Cas où il n'y a que des saveurs sans taille/unité\n",
    "                results.append({\n",
    "                    'saveurs': None,\n",
    "                    'packaging': None,\n",
    "                    'size': None,\n",
    "                    'unit': None,\n",
    "                    'misc': line.strip() if line.strip() else None\n",
    "                    })\n",
    "            # Cas sans taille/unité détectée\n",
    "            else:\n",
    "                results.append({\n",
    "                    'saveurs': saveurs,\n",
    "                    'packaging': None,\n",
    "                    'size': None,\n",
    "                    'unit': None,\n",
    "                    'misc': None\n",
    "                })\n",
    "\n",
    "    return results\n",
    "\n",
    "def merge_descriptif_dict(d_dict):\n",
    "    \"\"\"\n",
    "    Fusionne une liste de dictionnaires descriptifs en regroupant les saveurs par contenant (size).\n",
    "    - d_dict: liste de dictionnaires avec les clés 'saveurs', 'packaging', 'size', 'unit'\n",
    "    Retourne une liste de dictionnaires fusionnés.\n",
    "    \"\"\"\n",
    "    assert d_dict, \"DESCRIPTION should not be empty\"\n",
    "\n",
    "    # Vérifier que tous les dictionnaires ont les mêmes unités\n",
    "    # Met à jour d_dict en place si des unités différentes sont trouvées\n",
    "    units = [item['unit'] for item in d_dict if item['unit'] is not None]\n",
    "    if units and any(u != units[-1] for u in units):\n",
    "        last_unit = units[-1]\n",
    "        for item in d_dict:\n",
    "            if item['unit'] is not None and item['unit'] != last_unit:\n",
    "                # Concaténer packaging, size et unit pour misc\n",
    "                misc_parts = []\n",
    "                if item.get('packaging'):\n",
    "                    misc_parts.append(str(item['packaging']))\n",
    "                if item.get('size'):\n",
    "                    misc_parts.append(str(item['size']))\n",
    "                if item.get('unit'):\n",
    "                    misc_parts.append(str(item['unit']))\n",
    "                item['misc'] = \" \".join(misc_parts)\n",
    "                item['packaging'] = None\n",
    "                item['size'] = None\n",
    "                item['unit'] = None\n",
    "\n",
    "    # Définir 'packaging' comme la première valeur non nulle trouvée dans d_dict\n",
    "    first_packaging = next((item['packaging'] for item in d_dict if item.get('packaging')), None)\n",
    "    for item in d_dict:\n",
    "        if not item.get('packaging') and first_packaging:\n",
    "            item['packaging'] = first_packaging\n",
    "    # Extraire tous les 'size' non None, en gardant l'ordre et l'unicité\n",
    "    seen = set()\n",
    "    contenants = [item['size'] for item in d_dict if item['size'] is not None and not (item['size'] in seen or seen.add(item['size']))]\n",
    "\n",
    "    result = []\n",
    "    idx = 0\n",
    "    while idx < len(d_dict):\n",
    "        # Pour chaque contenant, regrouper les éléments jusqu'au dernier de ce contenant\n",
    "        for c in contenants:\n",
    "            indices_c = [i for i in range(idx, len(d_dict)) if d_dict[i]['size'] == c]\n",
    "            if not indices_c:\n",
    "                continue\n",
    "            last_idx = indices_c[-1]\n",
    "            # Inclure aussi les éléments sans 'size' avant le dernier de ce contenant\n",
    "            sub_d_dict = [d_dict[i] for i in range(idx, last_idx + 1) if d_dict[i]['size'] is None or d_dict[i]['size'] == c]\n",
    "            # Fusionner les saveurs en gardant l'ordre et l'unicité\n",
    "            saveurs = list(dict.fromkeys(s for item in sub_d_dict for s in item['saveurs']))\n",
    "            packaging = next((d['packaging'] for d in sub_d_dict if d['packaging']), None)\n",
    "            unit = next((d['unit'] for d in sub_d_dict if d['size'] == c and d['unit']), None)\n",
    "            misc = next((d['misc'] for d in sub_d_dict if d['misc']), None)\n",
    "            result.append({\n",
    "                'saveurs': saveurs,\n",
    "                'packaging': packaging,\n",
    "                'size': c,\n",
    "                'unit': unit,\n",
    "                'misc': misc\n",
    "            })\n",
    "            idx = last_idx + 1\n",
    "        break  # On sort après avoir traité tous les contenants\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b417f6ac",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "expected string or bytes-like object, got 'float'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[42]\u001b[39m\u001b[32m, line 77\u001b[39m\n\u001b[32m     72\u001b[39m                 df.loc[\u001b[38;5;28mlen\u001b[39m(df)] = new_row\n\u001b[32m     73\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m df.sort_values(\u001b[33m\"\u001b[39m\u001b[33mCLE\u001b[39m\u001b[33m\"\u001b[39m, ascending=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m---> \u001b[39m\u001b[32m77\u001b[39m data = \u001b[43mapply_sr_process\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     78\u001b[39m data[\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mPHOTO2\u001b[39m\u001b[33m\"\u001b[39m] = data[\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mPHOTO2\u001b[39m\u001b[33m\"\u001b[39m].astype(\u001b[33m'\u001b[39m\u001b[33mstr\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m     79\u001b[39m data = data[(~data[\u001b[33m'\u001b[39m\u001b[33mRONDE DES MARQUES\u001b[39m\u001b[33m'\u001b[39m]) & ((data[\u001b[33m'\u001b[39m\u001b[33mPHOTO2\u001b[39m\u001b[33m'\u001b[39m].notna()) | (data[\u001b[33m'\u001b[39m\u001b[33mDESCRIPTIF_2\u001b[39m\u001b[33m'\u001b[39m]!=\u001b[33m'\u001b[39m\u001b[33m'\u001b[39m) | (data[\u001b[33m'\u001b[39m\u001b[33mlen\u001b[39m\u001b[33m'\u001b[39m] > \u001b[32m1\u001b[39m))]\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[42]\u001b[39m\u001b[32m, line 55\u001b[39m, in \u001b[36mapply_sr_process\u001b[39m\u001b[34m(df)\u001b[39m\n\u001b[32m     53\u001b[39m value = df.at[idx, \u001b[33m\"\u001b[39m\u001b[33mPRIX AU KG DU LOT VIRTUEL\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m     54\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m i> \u001b[32m0\u001b[39m:            \n\u001b[32m---> \u001b[39m\u001b[32m55\u001b[39m     matches = \u001b[43mre\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfindall\u001b[49m\u001b[43m(\u001b[49m\u001b[43mregex_euro\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     56\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(matches) > \u001b[32m1\u001b[39m:\n\u001b[32m     57\u001b[39m         value = re.sub(matches[\u001b[32m2\u001b[39m], \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mp1\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m.replace(\u001b[33m\"\u001b[39m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m,\u001b[33m\"\u001b[39m\u001b[33m,\u001b[39m\u001b[33m\"\u001b[39m), value)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/FRANCAP/lib/python3.12/re/__init__.py:217\u001b[39m, in \u001b[36mfindall\u001b[39m\u001b[34m(pattern, string, flags)\u001b[39m\n\u001b[32m    209\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfindall\u001b[39m(pattern, string, flags=\u001b[32m0\u001b[39m):\n\u001b[32m    210\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Return a list of all non-overlapping matches in the string.\u001b[39;00m\n\u001b[32m    211\u001b[39m \n\u001b[32m    212\u001b[39m \u001b[33;03m    If one or more capturing groups are present in the pattern, return\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    215\u001b[39m \n\u001b[32m    216\u001b[39m \u001b[33;03m    Empty matches are included in the result.\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m217\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_compile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpattern\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflags\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfindall\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstring\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mTypeError\u001b[39m: expected string or bytes-like object, got 'float'"
     ]
    }
   ],
   "source": [
    "def apply_sr_process(df):\n",
    "    df['desc_dict'] = df.apply(lambda row: merge_descriptif_dict(parse_descriptif_lines_into_dict(row)), axis=1)\n",
    "    # Extraire la liste de toutes les saveurs (hors None ou chaînes vides)\n",
    "    df['len'] = df['desc_dict'].apply(lambda desc: sum(len(d.get('saveurs', [])) for d in desc))\n",
    "    df['CLE'] = df['CLE'].astype(int)*100\n",
    "    df['PRIX AU KG'].astype('object')\n",
    "    \n",
    "    units_t = {'g':1000, 'kg':1, 'mg':1000000, 'ml':1000, 'cl':100, 'l':1, 'default': 1}\n",
    "\n",
    "    #selectionner les conditions de degroupage, SR, et Catalogue:\n",
    "    isgroup = (~df['RONDE DES MARQUES']) & \\\n",
    "            ((df['PHOTO2'].notna()) | (df['DESCRIPTIF_2'].notna()) | (df['len'] > 1))\n",
    "\n",
    "    # Retourner la liste des clés (CLE) et des indices du DataFrame filtré\n",
    "    code = list(zip(df[isgroup]['CLE'], df[isgroup].index))\n",
    "    for cle, idx in code:\n",
    "        desc_dict = df.at[idx, 'desc_dict']\n",
    "        df.at[idx, 'SR'] = ''   # mettre le champs SR à nulle pour la ligne groupée\n",
    "        df.at[idx, 'CATALOG'] = 'X'  # mettre le champs CATALOG\n",
    "\n",
    "        px_net = df.at[idx, 'PVC NET']\n",
    "        px_max = df.at[idx, 'PVC MAXI']\n",
    "\n",
    "        len_saveurs = sum(len(d.get('saveurs', [])) for d in desc_dict)\n",
    "\n",
    "        for i, d in enumerate(desc_dict):\n",
    "            colname = f\"DESCRIPTIF{'' if i == 0 else f'_{i + 1}'}\"\n",
    "            value = '\\n'.join(filter(None, [\n",
    "                d.get('misc', ''),\n",
    "                ', '.join(d.get('saveurs', [])),\n",
    "                ' '.join(filter(None, [d.get('packaging'), d.get('size'), d.get('unit')]))\n",
    "            ]))\n",
    "            df.at[idx, colname] = value  # 👈 Modification directe sans slice ni copie\n",
    "\n",
    "            # Cherche un nombre entier dans d['packaging'], sinon retourne 1\n",
    "            match_cond = re.search(r\"\\b(\\d+)\\b\", str(d.get('packaging', '')))\n",
    "            conditionnement = int(match_cond.group(1)) if match_cond else 1\n",
    "\n",
    "            colpkg = f\"PRIX AU KG{'' if i==0 else f'_{i + 1}'}\"\n",
    "            value = df.at[idx, \"PRIX AU KG\"]\n",
    "            if i> 0:            \n",
    "                regex_euro = r\"\\b\\d{1,3}(?:[.,]\\d{3})*(?:[.,]\\d{2})?(?=\\s?€)\"\n",
    "                matches = re.findall(regex_euro, value)\n",
    "                \n",
    "                p1 = px_net * units_t.get(d['unit'], 1) / (conditionnement * float(d['size'].replace(',', '.')))\n",
    "                p2 = px_max * units_t.get(d['unit'], 1) / (conditionnement * float(d['size'].replace(',', '.')))\n",
    "                value = re.sub(matches[0], f\"{p1:.2f}\".replace(\".\",\",\"), value)\n",
    "                if len(matches) > 0:\n",
    "                    value = re.sub(matches[1], f\"{p2:.2f}\".replace(\".\",\",\"), value)\n",
    "            df.at[idx, colpkg] = value  # 👈 Modification directe sans slice ni copie\n",
    "\n",
    "            colpkglv = f\"PRIX AU KG DU LOT VIRTUEL{'' if i==0 else f'_{i + 1}'}\"\n",
    "            value = df.at[idx, \"PRIX AU KG DU LOT VIRTUEL\"]\n",
    "            if i> 0:            \n",
    "                matches = re.findall(regex_euro, value)\n",
    "                if len(matches) > 1:\n",
    "                    value = re.sub(matches[2], f\"{p1:.2f}\".replace(\".\",\",\"), value)\n",
    "            df.at[idx, colpkglv] = value  # 👈 Modification directe sans slice ni copie\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            indice=0\n",
    "            for sav in d.get('saveurs', []):\n",
    "                indice += 1\n",
    "                new_row = df.loc[idx].copy()\n",
    "                new_row['CLE'] = cle+indice\n",
    "                new_row['DESCRIPTIF'] = '\\n'.join(filter(None, [d.get('misc', ''), sav, ' '.join(filter(None, [d.get('packaging'), d.get('size'), d.get('unit')]))]))\n",
    "                new_row['SR'] = 'X'\n",
    "                new_row['CATALOG'] = ''\n",
    "                new_row['PRIX AU KG'] = new_row[colpkg]\n",
    "                df.loc[len(df)] = new_row\n",
    "    return df.sort_values(\"CLE\", ascending=True)\n",
    "\n",
    "\n",
    "\n",
    "data = apply_sr_process(df)\n",
    "data[f\"PHOTO2\"] = data[f\"PHOTO2\"].astype('str')\n",
    "data = data[(~data['RONDE DES MARQUES']) & ((data['PHOTO2'].notna()) | (data['DESCRIPTIF_2']!='') | (data['len'] > 1))]\n",
    "data = data[['CLE','SR','CATALOG','GENCOD','INTITULE','MARQUE','DESCRIPTIF','DESCRIPTIF_2','PRIX AU KG', 'PRIX AU KG_2', 'PRIX AU KG DU LOT VIRTUEL', 'PRIX AU KG DU LOT VIRTUEL_2']]\n",
    "\n",
    "data.head(40)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f39c1ca1",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "779cdeae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "FRANCAP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
